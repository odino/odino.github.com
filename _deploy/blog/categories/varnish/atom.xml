<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Varnish | Alessandro Nadalin]]></title>
  <link href="http://odino.org/blog/categories/varnish/atom.xml" rel="self"/>
  <link href="http://odino.org/"/>
  <updated>2014-02-26T15:43:49-05:00</updated>
  <id>http://odino.org/</id>
  <author>
    <name><![CDATA[Alessandro Nadalin]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Frontend web development is not as fun as it could be]]></title>
    <link href="http://odino.org/frontend-web-development-is-not-as-fun-as-it-should-be/"/>
    <updated>2013-11-10T19:53:00-05:00</updated>
    <id>http://odino.org/frontend-web-development-is-not-as-fun-as-it-should-be</id>
    <content type="html"><![CDATA[<p>I am writing this post in the middle of revamping
<a href="http://en-ae.namshi.com">Namshi&rsquo;s architecture</a>
with AngularJS, reverse proxies,
SPDY and HTTP APIs, because I
strongly believe in the future of these technologies and
that they are the de-facto cutting-edge solution for
most of the antipatterns that we&rsquo;ve seen so far:
monolithic applications, unscalable frontends,
limited protocols.</p>

<!-- more -->


<p><img class="right" src="/images/browsers.jpg"></p>

<p>So why would I rant about it? Well, this is not a real
rant but it&rsquo;s more of a retrospective on the <em>gotchas</em>
that we faced over the past months: I do <strong>really</strong>
enjoy all of this techs, but also
recognize that most of them are at a
very early stage and have their pitfalls when it comes
to develop real-world, scalable architectures.</p>

<p>The boring part&rsquo;s over, let&rsquo;s get into the real mess ;&ndash;)</p>

<h2>Reducing redirects?</h2>

<p>Suppose that you have a frontend, maybe built with AngularJS,
that proxies all the requests to an API, so if you request
<code>example.org/about</code>, your frontend actually gets the content
from <code>api.example.org/about</code>.</p>

<p>One of the things that you can start optimizing are the
round trips between the client and the server (very important
for mobile connections): for example,
instead of sending simple redirects from your API to the
frontend, you can return a <code>30X</code> and include the actual body
in the response; in this way, the client can:</p>

<ul>
<li>read the body of the response and work with it (output or whatever)</li>
<li>update the browser URL according to the <code>Location</code> header provided in the response with the <a href="http://diveintohtml5.info/history.html">browsers' history API</a></li>
</ul>


<p>NOT. SO. FAST.</p>

<p>Turns out that modern browsers intercept redirects and make an
additional HTTP request to the <code>Location</code> provided by the response.</p>

<p>This behavior is pretty useful in 98% of your use-cases, as
you dont have to take care of handling AJAX redirects on
your own and you have a pretty simple solution, using a
custom HTTP status
code, like <a href="http://stackoverflow.com/questions/199099/how-to-manage-a-redirect-request-after-a-jquery-ajax-call">278</a>, for the remaining 2% of scenarios.</p>

<p>NOT. SO. FAST. 2.</p>

<p>Of course, the magnificent <a href="http://www.zdnet.com/blog/networking/the-number-one-mobile-web-browser-googles-native-android-browser/2091">Android native browser</a>
will mess this up, thinking that <code>278</code> is an error code: so if, for
your HTTP request, you have a callback in case of success and
one in case of an error, the latter will be triggered.</p>

<p>How to deal with this?</p>

<p>Well, we decided to return straight <code>200 Ok</code> codes and include
2 custom headers, <code>X-Location</code> and <code>X-Status-Code</code>, that our
clients will parse to find out if they need to update the
browser&rsquo;s URL.</p>

<p>In pseudo-code:</p>

<p>```
res = http.get(&lsquo;api.example.org?search=BMW&rsquo;)</p>

<p>if (res.status_code === 200 &amp;&amp; res.headers.x-location) {</p>

<pre><code>browser.url = res.headers.x-location
</code></pre>

<p>}
```</p>

<p>In any case, with the growing amount of mobile clients, I think
it might make sense to start thinking of an appropriate process
to handle redirects, within the HTTP protocol, so that browsers
can just follow the spec: in my opinion we could use something
like <code>308 Transparent redirect</code> for this.</p>

<h2>Reverse proxies and HTTP cache</h2>

<p><img class="left" src="/images/varnish-cache.jpg"></p>

<p>Two of the most <a href="http://www.mnot.net/blog/2007/12/12/stale">important directives</a>
that you can use while taking advantage of the HTTP cache
are <code>stale-while-revalidate</code> and <code>stale-if-error</code>:
the former lets you return stale responses
while you revalidate the cache while the latter lets you serve
cached responses if your backend is down (<code>50X</code> errors).</p>

<p>Of course, you will need a reverse proxy in front
of your webserver in order to really take advantage of
these directives: <a href="http://www.squid-cache.org/">Squid</a> natively implements
both of them but, in our case, it was too much of a hassle to setup,
as it&rsquo;s bloated compared to its cousin <a href="https://www.varnish-cache.org/">Varnish</a>,
which doesn&rsquo;t natively implement <code>stale-*</code> directives instead.</p>

<p>Setting up Varnish to support those 2 directives it&rsquo;s a matter
of a few tries anyhow, as you can mimic the (almost) same
behaviors with Varnish&rsquo;s <a href="https://www.varnish-software.com/static/book/Saving_a_request.html#core-grace-mechanisms">grace and saint modes</a>.</p>

<h2>Android&rsquo;s native browser</h2>

<p><img class="right" src="/images/android.jpg"></p>

<p>Android, oh Android!</p>

<p>As we already saw, its native browser doesn&rsquo;t let you play around
with unconventional HTTP status codes<sup id='fnref:1'><a href='#fn:1' rel='footnote'>1</a></sup> and, on top of that,
<strong>it breaks the HTTP cache</strong>.</p>

<p>If you have a cacheable resource that you retrieve via AJAX,
the first request to retrieve will work, but as soon as you reload
the page and retrieve it a second time, the browser messes things up,
things that the request returned an invalid HTTP status code (<code>0</code>)
and aborts the process.</p>

<p>And yes, it&rsquo;s a <a href="http://opensourcehacker.com/2011/03/20/android-webkit-xhr-status-code-0-and-expires-headers/">known bug</a>.</p>

<h2>Performances on old devices</h2>

<p>And when I say old I mean stuff like the Galaxy S2 or S3, which are not <strong>that</strong> old
to be honest.</p>

<p>Performances are anyhow a huge concern when you start moving the logic into
the clients, as resources might be very limited: let&rsquo;s not forget that the
first generation of Galaxy &ndash; or even the iPhone 4 &ndash; were shipped out with
just 512mb of RAM; think of a JS-heavy app, which sucks up to 40/50mb of RAM:
how would that perform on those devices?</p>

<p>Let me tell you that: it&rsquo;d be very slow, and would even feel slower when CPUs
comes into the mix as &ndash; we&rsquo;ve witnessed it &ndash; to build DOM elements<sup id='fnref:2'><a href='#fn:2' rel='footnote'>2</a></sup>
it could take up to 4s. Of course, you can optimize it, but a brand new smartphone
wouldn&rsquo;t let you feel such <em>lag</em>: truth is that when you decide to go for a JS app
you need to take into account the time spent in optimizations for old devices,
as you&rsquo;ll surely need to invest on it.</p>

<h2>What a hard time debugging browser events</h2>

<p><img class="left" src="/images/chrome-devtools.png"></p>

<p>If you&rsquo;ve ever dug deep into optimizing browser events (HTML parsing, repainting and so on)
you probably know what I&rsquo;m talking about: the devtools are still at an early stage and
it becomes really tricky to be able to nail issues down or at least to efficiently
reverse engineer them; even though you have a breakdown of every browser event it&rsquo;s
actually pretty difficult to trace events back to their &ldquo;cause&rdquo;<sup id='fnref:3'><a href='#fn:3' rel='footnote'>3</a></sup>.</p>

<p>Chrome provides profiles and the timeline which are very useful resources, but you can&rsquo;t
really inspect that much as at a certain point you&rsquo;ll end up with <strong>a lot</strong> of events
like <em>HTML parsing</em> or <em>Function call</em> and only God knows where they exactly came from.</p>

<h2>Persistent sessions and credentials</h2>

<p><img class="right" src="/images/security.jpg"></p>

<p>Authenticating users might be tricky for frontend apps: you don&rsquo;t have the good old
(and heavy) PHP sessions that you can just fill up on you server, but you &ndash; at least
initially &ndash; can try to persist sessions on cookies or <a href="http://diveintohtml5.info/storage.html">localStorage</a>.</p>

<p>But even before thinking of storing sessions you have to deal with authenticating each
of your user from the app: granted that the HTTP basic auth is not good as
<a href="http://en.wikipedia.org/wiki/Basic_access_authentication#Security">it&rsquo;s flawed</a> and that
the <a href="http://en.wikipedia.org/wiki/Digest_access_authentication">digest auth</a> might be too simple,
you should start looking at alternative methods to authenticate and authorize your users,
preferrably using tokens.</p>

<p>As you probably figured out, there is no real standard mechanism of doing this, as some
providers rely on oAuth (both 2-* and 3-legged) and some on OpenID. Even Mozilla, a while ago,
came out with its own protocol, <a href="http://www.mozilla.org/en-US/persona/">Persona</a>, to solve this
problem.</p>

<p>We actually found out another &ldquo;protocol&rdquo; to store and transmit credentials through HTTP
APIs, the <em>Javascript Object Signing and Encryption</em> specification (<a href="https://datatracker.ietf.org/wg/jose/">JOSE</a>).</p>

<h2>A note on AngularJS and the Grunt ecosystem</h2>

<p>A glimpse of our <code>package.json</code>:</p>

<p>``` json
{
  &ldquo;devDependencies&rdquo;: {</p>

<pre><code>"grunt": "~0.4.1",
"grunt-contrib-copy": "~0.4.1",
"grunt-contrib-concat": "~0.3.0",
"grunt-contrib-coffee": "~0.7.0",
"grunt-contrib-uglify": "~0.2.0",
"grunt-contrib-compass": "~0.3.0",
"grunt-contrib-jshint": "~0.6.0",
"grunt-contrib-cssmin": "~0.6.0",
"grunt-contrib-connect": "~0.4.0",
"grunt-contrib-clean": "~0.4.1",
"grunt-contrib-htmlmin": "~0.1.3",
"grunt-contrib-imagemin": "~0.1.4",
"grunt-contrib-watch": "~0.5.3",
"grunt-usemin": "~0.1.11",
"grunt-rev": "~0.1.0",
"grunt-karma": "~0.4.3",
"grunt-open": "~0.2.0",
"matchdep": "~0.1.2",
...
</code></pre>

<p>```</p>

<p>As you see, the bower/node/grunt/angular ecosystem is still very young and,
from certain points of view, very immature (for example, <a href="https://github.com/gruntjs/grunt-contrib-connect/issues/9">SSL support in Grunt</a>
was added just 2 months ago).</p>

<p>So if you want to use these kind of technologies you must accept that, sometimes,
doing an <code>npm install</code> might break something, or that you will need to keep your deps
updated to the latest releases: it&rsquo;s all about <strong>go big or go home</strong>.</p>

<h2>Internet Explorer. As always.</h2>

<p><img class="right" src="/images/ie.png"></p>

<p>Eheh, there could not be a post about <em>web gotchas</em> without mentioning IE:
the lack of support for <a href="http://en.wikipedia.org/wiki/Cross-origin_resource_sharing">CORS</a>
in IE8 and IE9 is actually a real kicker for
efficiently implementing frontend apps that rely on a remote API
(<code>example.org</code> &ndash;> <code>api.example.org</code>), since CORS considers as cross-domain
even a request on a subdomain<sup id='fnref:4'><a href='#fn:4' rel='footnote'>4</a></sup>.</p>

<p>And no, there is no native escape strategy for this: you <strong>must</strong> extend the
<a href="http://www.w3.org/TR/XMLHttpRequest/">XHR</a> in order to make it capable of doing
cross-domain communication through Iframes, a strategy that even Google and Facebook
have implemented in the past; luckily there is some stuff already written for us,
so we can use the good <a href="https://github.com/jpillora/xdomain">xDomain</a> and
include it with the IE conditional comments.</p>

<p>But then, you would think, why not using xDomain for everything, and simply drop
CORS?</p>

<p>Well, there are a few things to consider:</p>

<ul>
<li>even though Google and Facebook are known to be using some trick like xDomain, it&rsquo;s
pretty strange that they havent released anything yet (might be that they don&rsquo;t consider
it a long-term option)</li>
<li>the native Android browser was known to have <a href="https://github.com/jpillora/xdomain/issues/19">issues with this library</a></li>
<li>CORS is a growing standard that has been widely adopted by the community</li>
<li>the <a href="https://github.com/jpillora/xdomain/blob/gh-pages/dist/xdomain.js">code</a> looks kind of cryptic</li>
</ul>


<p>All in all, we didnt feel like using xDomain for everything, as we are just using
it for IE8/9<sup id='fnref:5'><a href='#fn:5' rel='footnote'>5</a></sup>: <a href="https://github.com/jpillora">Jaime</a> did a great job
implementing it but I personally feel that it might be <strong>too much</strong> to just blindly
rely on it for cross-domain communications.</p>

<h2>CORS and HTTP headers</h2>

<p>Deciding to go with CORS it&rsquo;s just half of it, as the other half consists
into actually implementing CORS on both your clients and servers (APIs): it&rsquo;s
worth mentioning that the specification is really strict when it comes to
<strong>send and manipulate custom HTTP headers</strong> (like the <code>X-Location</code> that we
saw at the beginning of this post).</p>

<p>If you wanna send a custom header you will need to specify it in the
<code>Access-Control-Request-Headers</code> header:</p>

<p><code>
Access-Control-Request-Headers: X-My-Custom-Header
</code></p>

<p>and if you want your clients to be able to access some of the response&rsquo;s headers you will
need to declare them as &ldquo;accessible&rdquo;:</p>

<p><code>
Access-Control-Expose-Headers: X-My-Other-Header, X-...
</code></p>

<h2>How to do RUM?</h2>

<p>Another good question (and I don&rsquo;t have an answer so far) is how to measure
performances as felt by the end-user (<a href="http://en.wikipedia.org/wiki/Real_user_monitoring">Real User Monitoring</a>),
since AngularJS loads once and then never triggers server-side measurable events
other than HTTP requests to your APIs: the API&rsquo;s response times cannot be taken
into account as you wouldn&rsquo;t measure the
performance perceived by the end user &ndash; remember, JS frameworks add HTML parsing,
data-binding and so on on top of the cake.</p>

<p>We still have to figure out how we will implement RUM in our apps,
if you have any suggestion it would be highly appreciated!</p>

<h2>All in all&hellip;</h2>

<p>Developing on the frontend is an amazing experience that has some drawbacks, like on
any platform: beware of the specs (like CORS) and gotchas (IE, Android&rsquo;s native browser) and you will
enjoy it to the max!</p>

<hr />

<p><em>P.S. Thanks to <a href="https://github.com/hzarka">HZ</a> and <a href="https://github.com/AdamQuadmon">AdamQuadmon</a>
for passively contributing to this post, sharing with me and the rest of our team this amazing
and tortuous experience</em></p>

<hr />

<p><div class="footnotes">
<span>
Notes
</span>
	<ol>
		<li id='fn:1'>Which might be fair, as even Chrome has some funny behaviors <a href='#fnref:1' rev='footnote'>↩</a></li><li id='fn:2'>Not so many DOM elements! <a href='#fnref:2' rev='footnote'>↩</a></li><li id='fn:3'>Chrome's Devtools "Profiles" are probably the best resource you can use to backtrace stuff <a href='#fnref:3' rev='footnote'>↩</a></li><li id='fn:4'>Which makes sense when you have platforms like Tumblr <a href='#fnref:4' rev='footnote'>↩</a></li><li id='fn:5'>BTW IE11 is out, so there's even more hope <a href='#fnref:5' rev='footnote'>↩</a></li>
	</ol>
</div>
</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Installing and configuring Varnish on Ubuntu]]></title>
    <link href="http://odino.org/installing-and-configuring-varnish-on-ubuntu/"/>
    <updated>2011-02-09T02:29:00-05:00</updated>
    <id>http://odino.org/installing-and-configuring-varnish-on-ubuntu</id>
    <content type="html"><![CDATA[<p>On a brand new debian/*ubuntu distro, there are only a couple steps to do in order to make Varnish <del>act as a proxy</del> do its job in front of apache.</p>

<!-- more -->


<p>Installation:</p>

<p><code>
sudo apt-get install varnish
</code></p>

<p>then you need to configure it to listen to the <code>:80</code> port, editing <code>/etc/default/varnish</code>:</p>

<p>```
DAEMON_OPTS=&ldquo;-a :80 \</p>

<pre><code>         -T localhost:6082 \
         -f /etc/varnish/default.vcl \
         -S /etc/varnish/secret \
         -s file,/var/lib/varnish/$INSTANCE/varnish_storage.bin,1G"
</code></pre>

<p>```</p>

<p>and telling it to forward requests to apache ( we&rsquo;re gonna make it listen to the <code>8090</code> ), into the <code>/etc/varnish/default.vcl</code>:</p>

<p>```
backend apache {</p>

<pre><code>    .host = "127.0.0.1";
    .port = "8090";
</code></pre>

<p>}
sub vcl_fetch {</p>

<pre><code>    remove req.http.X-Forwarded-For;
    set    req.http.X-Forwarded-For = req.http.rlnclientipaddr;
    return(deliver);
</code></pre>

<p>}
```</p>

<p>Then it&rsquo;s time to tell apache it has to listen to a new port, in <code>/etc/apache2/ports.conf</code>:</p>

<p><code>
NameVirtualHost *:8090
Listen 127.0.0.1:8090
</code></p>

<p>Make sure the hosts in your <code>/etc/apache2/httpd.conf</code> listen to <code>:*</code> or <code>:8090</code>, then you can start the services:</p>

<p><code>
/etc/init.d/apache2 start
/etc/init.d/varnish start
</code></p>

<p>Now you have varnish responding to all the hosts on the <code>:80</code>: if you experience some troubles try to go deeper with this <a href="http://www.howtoforge.com:8080/putting-varnish-in-front-of-apache-on-ubuntu-debian">extended guide</a>.</p>
]]></content>
  </entry>
  
</feed>
