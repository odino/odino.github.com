<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Category: Scaling | Alessandro Nadalin]]></title>
  <link href="http://odino.org/blog/categories/scaling/atom.xml" rel="self"/>
  <link href="http://odino.org/"/>
  <updated>2014-07-05T23:30:58+04:00</updated>
  <id>http://odino.org/</id>
  <author>
    <name><![CDATA[Alessandro Nadalin]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Search Engines Are Making the Web Slower]]></title>
    <link href="http://odino.org/search-engines-are-making-the-web-slower/"/>
    <updated>2012-04-07T10:00:00+04:00</updated>
    <id>http://odino.org/search-engines-are-making-the-web-slower</id>
    <content type="html"><![CDATA[<p>Like it or not, pushing the work to the clients is
a tecnique which made the web able to scale the way
it is now: <strong>search engines are making it slower</strong> and
less scalable, as they don&rsquo;t want us to do so.</p>

<!-- more -->


<p>The problem is that JavaScript &ndash; the <em>creepy</em> JavaScript &ndash;
is now recognized as a first-level programming language<sup id='fnref:1'><a href='#fn:1' rel='footnote'>1</a></sup>,
although SE are around since more than a decade: thus,
crawlers and spiders, although able to interpretate basic
JS code, cannot do more complex stuff, like managing
<a href="http://handlebarsjs.com/">Handlerbars</a> or <a href="http://mnot.github.com/hinclude/">HInclude</a>.</p>

<p>Or, at least, we don&rsquo;t know if they can.</p>

<p>There would be a workaround to this kind of issue, by just
<strong>serving different content for JS-aware clients</strong>, so that a
spider could see the whole resource without the need of
executing JS code: a workaround that would cost in terms of
development time, but still an acceptable workaround.</p>

<p>The problem, here, is that tis tecnique, known as <a href="http://en.wikipedia.org/wiki/Cloaking">cloacking</a>
is part of the <a href="http://en.wikipedia.org/wiki/Search_engine_optimization#White_hat_versus_black_hat">black hat SEO</a> list, so you basically can&rsquo;t take
advantage of it as malicious web developers would use
cloacking to serve keyword-stuffed contents to bots and
&ldquo;normal&rdquo; webpages to humans, and this is something you
really want to avoid, since SERPs' relevance is an
important part of a user&rsquo;s eb experience.</p>

<p>But, at least, we don&rsquo;t know how search engines would react
to the workaround I just explained.</p>

<h2>What do we need?</h2>

<p>We should have clarifications from SE vendors, to know whether
they are able or not to let us take advantage of great JS-based
technologies able to make our applications scale better, or &ndash; better &ndash;
have fully JS-aware spiders and crawlers, able to elaborate
resources like real-world browsers.</p>

<p>It&rsquo;s not about me, it&rsquo;s not about you, it&rsquo;s about the web: a faster,
and <strong>definitely better</strong>, web.</p>

<p><div class="footnotes">
<span>
Notes
</span>
	<ol>
		<li id='fn:1'>Mainly because of the NodeJS hype <a href='#fnref:1' rev='footnote'>â†©</a></li>
	</ol>
</div>
</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Scaling Asynchronously Through HInclude]]></title>
    <link href="http://odino.org/scaling-through-hinclude/"/>
    <updated>2012-02-24T10:50:00+04:00</updated>
    <id>http://odino.org/scaling-through-hinclude</id>
    <content type="html"><![CDATA[<p>Since it&rsquo;s been a while that I spread the idea of
having <a href="/edge-side-includes-how-to-spare-terabytes-every-day/">ESI on the client side</a>,
someone pointed out that a good solution, technically
different from the one I personally proposed, would
be to use JavaScript to and asynchronous sub-requests.</p>

<!-- more -->


<p>There is a small JS library, written by the good
<a href="http://www.mnot.net/">Mark Nottingham</a><sup id='fnref:1'><a href='#fn:1' rel='footnote'>1</a></sup>,
called <a href="http://mnot.github.com/hinclude/">HInclude</a>,
which does this kind of job.</p>

<h2>The problem</h2>

<p>Consider that you have an high-traffic websites which has
some parts of its webpages that rarely change, like the header,
the footer and some sidebars: why should you regenerate all
those parts at every request?</p>

<p><a href="http://www.w3.org/TR/esi-lang">ESI</a> solves this kind
of problem, but requires you to make a request through the
network, as you need, at least, to hit the reverse proxy,
which then handles the composition on a resource with
sub-resources.</p>

<p>As I <a href="/edge-side-includes-how-to-spare-terabytes-every-day/">stated earlier</a>,
this is not an optimal approach for every <em>use-case</em>, so you
definitely should try to use local caches (your users) to
scale better.</p>

<h2>The solution</h2>

<p>HInclude fits perfectly in this context, as you only need to
include the JS and add a namespace declaration to your documents:</p>

<p>``` html
  <html xmlns:hx="http://purl.org/NET/hinclude"></p>

<pre><code>&lt;head&gt;
  &lt;script src="http://odino.org/lib/hinclude.js"
   type="text/javascript"&gt;&lt;/script&gt;
</code></pre>

<p>```</p>

<p>whenever you need to aggregate data from a sub-resource you
only need to <strong>add an hinclude tag</strong>:</p>

<p><code>html
&lt;hx:include src="http://odino.org/header.html"&gt;&lt;/hx:include&gt;
</code></p>

<p>You can specify a default content &ndash; if the user has not javascript
or whatever &ndash; and it provides a nice behaviour when the sub-request
generates an error (status codes different from <code>200</code> and <code>304</code>), as
it adds an <code>hinclude_$statusCode</code> class to the tag.</p>

<h2>A dummy benchmark</h2>

<p>I provide here a benchmark, a simple and silly one, as you should be
already able to understand the power of HInclude.</p>

<p>First of all let&rsquo;s create a simple response, which aggregates header
and footer directly from PHP, as we are used to do:</p>

<p>``` php index_no_hinclude.php
<html></p>

<pre><code>&lt;head&gt;
&lt;/head&gt;
&lt;body&gt;
  &lt;p&gt;
    &lt;?php include 'header.php'; ?&gt;
  &lt;/p&gt;
  &lt;div class="main"&gt;
    &lt;!-- start slipsum code --&gt;

    Look, just because I don't be givin' no man a foot massage don't make it right for Marsellus to throw Antwone into a glass motherfuckin' house, fuckin' up the way the nigger talks. Motherfucker do that shit to me, he better paralyze my ass, 'cause I'll kill the motherfucker, know what I'm sayin'?

    &lt;!-- please do not remove this line --&gt;

    &lt;div style="display:none;"&gt;
    &lt;a href="http://slipsum.com"&gt;lorem ipsum&lt;/a&gt;&lt;/div&gt;

    &lt;!-- end slipsum code --&gt;
  &lt;/div&gt;
  &lt;p&gt;
    &lt;?php include 'footer.php'; ?&gt;
  &lt;/p&gt;
&lt;/body&gt;
</code></pre>

<p></html>
```</p>

<p>and then the header and footer files:</p>

<p>``` php header.php
&lt;?php usleep(200000); ?></p>

<!-- start slipsum code -->


<p>You think water moves fast? You should see ice. It moves like it has a mind. Like it knows it killed the world once and got a taste for murder. After the avalanche, it took us a week to climb out. Now, I don&rsquo;t know exactly when we turned on each other, but I know that seven of us survived the slide&hellip; and only five made it out. Now we took an oath, that I&rsquo;m breaking now. We said we&rsquo;d say it was the snow that killed the other two, but it wasn&rsquo;t. Nature is lethal but it doesn&rsquo;t hold a candle to man.</p>

<!-- please do not remove this line -->




<div style="display:none;">
<a href="http://slipsum.com">lorem ipsum</a></div>




<!-- end slipsum code -->


<p>```</p>

<p>``` php footer.php
&lt;?php usleep(200000); ?></p>

<!-- start slipsum code -->


<p>Normally, both your asses would be dead as fucking fried chicken, but you happen to pull this shit while I&rsquo;m in a transitional period so I don&rsquo;t wanna kill you, I wanna help you. But I can&rsquo;t give you this case, it don&rsquo;t belong to me. Besides, I&rsquo;ve already been through too much shit this morning over this case to hand it over to your dumb ass.</p>

<!-- please do not remove this line -->




<div style="display:none;">
<a href="http://slipsum.com">lorem ipsum</a></div>




<!-- end slipsum code -->


<p>```</p>

<p>Bear in mind that I use</p>

<p><code>php
&lt;?php usleep(200000); ?&gt;
</code></p>

<p>to simulate some php code execution (<code>200ms</code> seems a
reasonable amount of time &ndash; inspired by one of our
live projects).</p>

<p>I took a look at Chrome&rsquo;s timeline bar to get an idea of
the average time spent for rendering this resource, and it
was <code>~450ms</code>.</p>

<p>If you try to use HInclude, just create a new page:</p>

<p>``` html index_hinclude.php
<html xmlns:hx="http://purl.org/NET/hinclude"></p>

<pre><code>&lt;head&gt;
  &lt;script src="src/hinclude.js"
   type="text/javascript"&gt;&lt;/script&gt;
&lt;/head&gt;
&lt;body&gt;
  &lt;p&gt;
    &lt;hx:include src="header.php"&gt;&lt;/hx:include&gt;
  &lt;/p&gt;
  &lt;div class="main"&gt;
    &lt;!-- start slipsum code --&gt;

    Look, just because I don't be givin' no man a foot massage don't make it right for Marsellus to throw Antwone into a glass motherfuckin' house, fuckin' up the way the nigger talks. Motherfucker do that shit to me, he better paralyze my ass, 'cause I'll kill the motherfucker, know what I'm sayin'?

    &lt;!-- please do not remove this line --&gt;

    &lt;div style="display:none;"&gt;
    &lt;a href="http://slipsum.com"&gt;lorem ipsum&lt;/a&gt;&lt;/div&gt;

    &lt;!-- end slipsum code --&gt;
  &lt;/div&gt;
  &lt;p&gt;
    &lt;hx:include src="footer.php"&gt;&lt;/hx:include&gt;
  &lt;/p&gt;
&lt;/body&gt;
</code></pre>

<p></html>
<code>``
and add, in</code>header.php<code>and</code>footer.php`, a caching header,
which HInclude will made the browser take advantage of:</p>

<p><code>php At the top of header.php and footer.php
&lt;?php header('Cache-Control: max-age=3600'); ?&gt;
</code></p>

<p>For the first user requests it will require <code>~220ms</code> to render
the whole page: this is a pretty good starting gain, as we are
<strong>requesting header and footer in parallel</strong>, but as you retrieve
the page for the second time, performances will incredibly
improve, down to <code>~40/50ms</code>: it&rsquo;s, basically, a <strong>90% performance
gain</strong>, but you should be aware that the biggest load time should
be spent within the main body of the page, that I just ignored in
this example; but gaining almost a half second for each pageview
is just a great goal achieved.</p>

<p>As pointed out by other people on twitter, HInclude has a few
drawbacks &ndash; think about
<a href="https://twitter.com/#!/lyrixx/status/172849248868646912">SEO</a> &ndash;
but you should be able to use it with contents that rarely need
to play a major role in your SEO strategy (eg. never use HInclude
to retrieve the body of a blog post<sup id='fnref:2'><a href='#fn:2' rel='footnote'>2</a></sup>).</p>

<p><div class="footnotes">
<span>
Notes
</span>
	<ol>
		<li id='fn:1'>You should know him for his contributions to the HTTP specification, httpbis, cache channels and &ndash; in general &ndash; the HTTP cache <a href='#fnref:1' rev='footnote'>â†©</a></li><li id='fn:2'>Recently Matt Cutts came out with the assertion that Googlebot is capable to understand basic JS redirects, so&hellip; there&rsquo;s hope <a href='#fnref:2' rev='footnote'>â†©</a></li>
	</ol>
</div>
</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Edge Side Includes, How to Spare Terabytes Every Day]]></title>
    <link href="http://odino.org/edge-side-includes-how-to-spare-terabytes-every-day/"/>
    <updated>2012-01-20T14:15:00+04:00</updated>
    <id>http://odino.org/edge-side-includes-how-to-spare-terabytes-every-day</id>
    <content type="html"><![CDATA[<p>I have an idea for an RFC that I would like to write, based on some thoughts I
had in the last months.</p>

<!-- more -->


<p>Lots of you probably know <a href="http://www.w3.org/TR/esi-lang">ESI</a>, the specification
written by <a href="http://www.akamai.com/">Akamai</a> and <a href="http://www.oracle.com/index.html">Oracle</a>
back in 2001.</p>

<p>It basically consists in a XML dialect which lets <a href="http://en.wikipedia.org/wiki/Reverse_proxy">reverse proxies</a>
(eg. <a href="https://www.varnish-cache.org/">Varnish</a>) cache fragments of your webpages
in order not to hit your application for output fragments that can be re-used
across many clients.</p>

<p>``` html A webpage including an ESI tag
<html>
  <head></p>

<pre><code>...
</code></pre>

<p>  </head>
  <body></p>

<pre><code>...

pile of HTML

...

&lt;esi:include src="http://example.com/footer.html" /&gt;
</code></pre>

<p>  </body>
</html>
```</p>

<p>A <strong>really good presentation</strong> about ESI is <a href="http://www.slideshare.net/fabpot/caching-on-the-edge/99">Caching On The Edge</a>
, by <a href="http://fabien.potencier.org/">Fabien Potencier</a>.</p>

<h2>ESI&rsquo;s context</h2>

<p>ESI is a really great technology that recently gained hype, in my ecosystem (PHP),
thanks to the Symfony2 architecture, fully embracing the HTTP specification:
consider that Symfony2 has <strong>no application-level caching layer</strong>, so everything
is done with the HTTP cache, and ESI is the solution for really dynamic webpages.</p>

<p>&hellip;but who&rsquo;s responsible of processing ESI fragments? Digging some more, an esi
processor can be a <a href="http://rack.rubyforge.org/">middleware in your architecture</a>
, a reverse proxy or a <a href="http://symfony.com/doc/2.0/book/http_cache.html#using-edge-side-includes">software component</a>
; basically any kind of software implementing the ESI specification.</p>

<p>But hey, all this kind of things are softwares that lie on the server side.</p>

<h2>A different approch</h2>

<p>I was thinking about pushing ESI to the client side:</p>

<p>``` html The response retrieved with the browser would generate lots of subrequests
<html>
  <head></p>

<pre><code>...
</code></pre>

<p>  </head>
  <body></p>

<pre><code>&lt;esi:include src="http://example.com/header.html" /&gt;
&lt;esi:include src="http://example.com/navigation.html" /&gt;
&lt;esi:include src="http://example.com/foo.html" /&gt;
&lt;esi:include src="http://example.com/bar.html" /&gt;
&lt;esi:include src="http://example.com/footer.html" /&gt;
</code></pre>

<p>  </body>
</html>
```</p>

<p>Seems a bad idea, since, if the browser is capable to merge different fragments, retrieved
with different HTTP requests, for assembling a really simple webpage you would
need to hit your application much more times than with a single request, so there
is no real need to ask for ESI support in clients, in this scenario.</p>

<p>But there&rsquo;s a <em>real-world</em> application of ESI on the client side that should
<strong>save lot of traffic</strong> over the internet and <strong>lot of bandwith</strong>.</p>

<p><strong>Rarely-changing output fragments</strong>.</p>

<p>A RCOF &ndash; sorry for this bad acronym &ndash; is everything that can be <strong>cached for
relatively long time</strong> (talking more about days than hours), like Facebook&rsquo;s
footer or your google analytics JS code.</p>

<p><img class="center" src="/images/fb.footer.png"></p>

<h2>The use-case</h2>

<p>Why should we always transport Facebook&rsquo;s footer over the network?</p>

<p>We don&rsquo;t need it: once the user landed on his profile page, as he jumps
to other FB pages, <strong>the footer it&rsquo;s always the same</strong>, and <strong>should be retrieved from
the client&rsquo;s cache</strong> instead of being sent over the network.</p>

<p>This means that once you send your response</p>

<p>``` html Your profile page
<body></p>

<pre><code>&lt;h1&gt;My Profile!&lt;/h1&gt;

...

&lt;esi:include src="http://example.com/footer.html" /&gt;
</code></pre>

<p></body>
```</p>

<p>the browser makes an additional request to retrieve the footer and then, on subsequent
requests, also <strong>on different webpages</strong>, it can use the cached fragment:</p>

<p>``` html Facebook help center
<body></p>

<pre><code>&lt;h1&gt;Hi n00b, how can we help you?&lt;/h1&gt;

...

&lt;esi:include src="http://example.com/footer.html" /&gt;
</code></pre>

<p></body>
```</p>

<p>because it recognizes that fragment has been already retrieved once you requested
the &ldquo;Your profile&rdquo; page.</p>

<p>You probably don&rsquo;t get the great aspect of ESI on the client side, so <strong>carefully
read the next chapter</strong>.</p>

<h2>A few numbers</h2>

<p>Facebook&rsquo;s footer is about <code>1.4k</code>:</p>

<p>``` html</p>

<div id="pageFooter" data-referrer="page_footer">
    <div id="contentCurve"></div>
    <div class="clearfix" id="footerContainer">
        <div class="mrl lfloat" role="contentinfo">
            <div class="fsm fwn fcg">
                <span> Facebook Â© 2012</span> Â· <a rel="dialog" href="http://odino.org/ajax/intl/language_dialog.php?uri=http%3A%2F%2Fwww.facebook.com%2Fpress%2Finfo.php%3Fstatistics" title="Use Facebook in another language.">English (US)</a>
            </div>
        </div>
        <div class="navigation fsm fwn fcg" role="navigation">
            <a href="http://www.facebook.com/facebook" accesskey="8" title="Read our blog, discover the resource center, and find job opportunities.">About</a> Â· <a href="http://www.facebook.com/campaign/landing.php?placement=pf&amp;campaign_id=402047449186&amp;extra_1=auto" title="Advertise on Facebook.">Advertising</a> Â· <a href="http://www.facebook.com/pages/create.php?ref_type=sitefooter" title="Create a Page">Create a Page</a> Â· <a href="http://developers.facebook.com/?ref=pf" title="Develop on our platform.">Developers</a> Â· <a href="http://www.facebook.com/careers/?ref=pf" title="Make your next career move to our awesome company.">Careers</a> Â· <a href="http://www.facebook.com/privacy/explanation" title="Learn about your privacy and Facebook.">Privacy</a> Â· <a href="http://www.facebook.com/legal/terms?ref=pf" accesskey="9" title="Review our terms of service.">Terms</a> Â· <a href="http://www.facebook.com/help/?ref=pf" accesskey="0" title="Visit our Help Center.">
                Help
            </a>
        </div>
    </div>
</div>


<p>```</p>

<p>while an ESI fragment is <code>0.5k</code>:</p>

<p><code>xml
&lt;esi:include src="http://facebook.com/footer" /&gt;
</code></p>

<p>Calculating how much traffic the internet needs to sustain with the 2
approaches, traditional and ESIsh, is trivial:</p>

<ul>
<li>Facebook has something more than <a href="http://www.facebook.com/press/info.php?statistics">400M daily users</a></li>
<li>it has <a href="http://www.alexa.com/siteinfo/facebook.com">12 pageviews per user</a></li>
<li>retrieving the footer the traditional way, we add <code>1.5k</code> of data each users' request</li>
<li>retrieving it with ESI, we add <code>1.5k</code> of data for the first users' request,
<code>0.5k</code> for the consequent ones</li>
</ul>


<p>Then we can extrapolate some data:</p>

<p>``` html Facebook daily pageviews
daily users * avg pageviews</p>

<p>400M * 12</p>

<p>4800M
```</p>

<p>``` html Data traffic without client-side ESI
daily pageviews * footer fragment weight</p>

<p>4800M * 1.4k</p>

<p>~6.25 terabytes
```</p>

<p>``` html Data traffic with client-side ESI
(first requests * footer fragment weight) + ((daily pageviews &ndash; first pageviews) * ESI tag weight)</p>

<p>(400M * 1.4k) + ((4800M &ndash; 400M) * 0.5k)</p>

<p>~2.57 terabytes
```</p>

<p>So, just for the footer, <strong>facebook could decrease the internet traffic by 2 and a
half terabytes <em>per day</em></strong>, just looking at its footer.</p>

<p>It&rsquo;s obvious that <strong>this approach rewards facebook</strong> (it processes less stuff on his
side, whether it uses a reverse proxy as gateway cache or not), ISPs and the final
user, who&rsquo;s taking advantage of a (more) <strong>lean network</strong>.</p>

<p>If you enlarge your vision, think about sites like Google, LinkedIN, twitter and all
those web applications which send <strong>useless pieces of HTTP responses over the
internet</strong>.</p>

<h2>Client side ESI invalidation</h2>

<p>If you are scared about invalidating this kind of cache, the solution would be
really easy:</p>

<p>``` html Facebook before updating the footer
<html>
  <head></p>

<pre><code>...
</code></pre>

<p>  </head>
  <body></p>

<pre><code>...

pile of FB code

...

&lt;esi:include src="http://example.com/footer.html?v=1" /&gt;
</code></pre>

<p>  </body>
</html>
```</p>

<p>``` html Facebook after updating the footer
<html>
  <head></p>

<pre><code>...
</code></pre>

<p>  </head>
  <body></p>

<pre><code>...

pile of FB code

...

&lt;esi:include src="http://example.com/footer.html?v=2" /&gt;
</code></pre>

<p>  </body>
</html>
```</p>

<p>Note the <strong>revision change in the ESI tag</strong>, something we already, daily, use for
managing <a href="http://muffinresearch.co.uk/archives/2008/04/08/automatic-asset-versioning-in-django/">static assets' caching</a>.</p>

<h2>This is not a panacea</h2>

<p>I don&rsquo;t wanna sound arrogant proposing this tecnique, but I would really like to
<strong>get feedbacks about such this kind of approach</strong>: as stated, this can be a
great plus for the global network but its <strong>limited to RCOF</strong>.</p>

<p>The only aspect I haven&rsquo;t considered yet is the second HTTP request the browser
needs to do to retrieve the fragment, once, parsing the response, it finds an ESI
tag: since I really don&rsquo;t know how to calculate how it affects the network,
so any kind of help would be appreciated.</p>

<p>The aim of this post is to consider if <strong>browser vendors should really start thinking
about implementing ESI processors</strong> directly in their products, for a better, faster
and leaner web.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Real-time Scaling: When NoSQL Almost Wins, HTTP Almost Wins, and the Customer Smiles]]></title>
    <link href="http://odino.org/real-time-scaling-when-nosql-almost-wins-http-almost-wins-and-the-customer-smiles/"/>
    <updated>2011-05-06T15:42:00+04:00</updated>
    <id>http://odino.org/real-time-scaling-when-nosql-almost-wins-http-almost-wins-and-the-customer-smiles</id>
    <content type="html"><![CDATA[<p>There&rsquo;s a common goal that NoSQL and ESI share together: consistency.</p>

<p>Since <a href="http://www.slideshare.net/odino/http-cache-pug-rome-03292011/2">the web is inconsistent</a>, we should be able to find some hacks to make it more consistent and satisfy both us, reducing bandwidth, traffic and CPU load, and the end-user, decreasing the latency of our services.</p>

<!-- more -->


<h2>Edge Side Includes</h2>

<p>ESI is a specification written 10 years ago in order to let the reverse proxies being able to include <em>{insert media type here}</em> fragments in HTTP responses.</p>

<p>It&rsquo;s so useful because it let&rsquo;s you take advantage of HTTP&rsquo;s native caching specification without recurring to application caches for really dynamic pages.</p>

<p>An ESI tag is pretty straightforward:</p>

<p>``` xml
<html>
  <head>&hellip;</head>
  <body></p>

<pre><code>...
  &lt;esi:include src="http://odino.org/footer.html" /&gt;
...
</code></pre>

<p>  </body>
</html>
```</p>

<p>So, as you see, caching directives for webpages' fragments are now a matter of the protocol ( HTTP, in most cases ) and not of the application ( Symfony, DotNetNuke, Joomla, WordPress, Drupal, Django, Django REST framework, Ruby, Sinatra, &hellip; ).</p>

<p>This is so awesome because:</p>

<ul>
<li>it lets you scale when really dynamic data needs to be sent over the network</li>
<li>you don&rsquo;t have to re-invent the wheel with your application&rsquo;s caching layer</li>
<li>caching directives are a matter of the protocol, thus, if you&rsquo;ll change your application, caching configuration won&rsquo;t change</li>
</ul>


<h2>NoSQL</h2>

<p>The NoSQL movement is really old, but has been highlighted in the last 2/3 years.</p>

<p>At the italian NoSQLday I listened a talk about Redis and another one about SQL antipatterns which helped me contextualizing this DBMS: a few of them are out there in order to help you increase your performances without recurring to a caching mechanism, having the possibility to <strong>really</strong> show really real-time data.</p>

<p>Most of them are so fast, damn.</p>

<h2>A common goal</h2>

<p>Since, as we see, a few players are pointing towards a more consistent web, we should assume that this is the way to drive tecnology through: organizations like Facebook have to need to scale to milions of users mantaining the appearance of a real-time service, and the more they reach their goals, the more our customers pretend to act like them.</p>

<p>In order to &ldquo;<em>real-time scale</em>&rdquo; you can use a technology born a decade ago or another one which is on everyone&rsquo;s lips since a couple years.</p>

<p>The choice is yours: tools are always tools, but the architecture&rsquo;s design is something we, only we, can manage.</p>
]]></content>
  </entry>
  
</feed>